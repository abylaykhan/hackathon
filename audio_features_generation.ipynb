{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144c3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token='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')\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def trim_audio(file_path, output_path, start_sec=20, end_sec=80):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    duration_sec = len(audio) / 1000  # длительность аудио в секундах\n",
    "\n",
    "    start_ms = start_sec * 1000\n",
    "    end_ms = end_sec * 1000\n",
    "\n",
    "    # Если файл короче конца обрезки — обрежем до конца доступного\n",
    "    if end_ms > len(audio):\n",
    "        end_ms = len(audio)\n",
    "\n",
    "    if start_ms >= end_ms:\n",
    "        start_ms = 0\n",
    "\n",
    "    trimmed = audio[start_ms:end_ms]\n",
    "    trimmed.export(output_path, format=\"wav\")  # можно заменить формат, если нужно\n",
    "\n",
    "input_dir = \"new_audiofiles/audiofiles\"\n",
    "output_dir = \"trimmed_audios\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".wav\"):  # или .wav и т.д.\n",
    "        in_path = os.path.join(input_dir, filename)\n",
    "        out_path = os.path.join(output_dir, filename)\n",
    "        trim_audio(in_path, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abd750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05afa7971e21400684a32f57b29f1af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\n",
      "cannot reshape tensor of 0 elements into shape [-1, 0] because the unspecified dimension size -1 can be any value and is ambiguous\n"
     ]
    }
   ],
   "source": [
    "audio_dir = \"trimmed_audios\"\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(audio_files):\n",
    "    try:\n",
    "        filepath = os.path.join(audio_dir, filename)\n",
    "        diarization = pipeline(filepath)\n",
    "\n",
    "        segments = []\n",
    "        speaker_durations = defaultdict(float)\n",
    "        speaker_turns = defaultdict(int)\n",
    "        audio_end = 0.0\n",
    "\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            start, end = turn.start, turn.end\n",
    "            duration = end - start\n",
    "            segments.append((start, end, duration, speaker))\n",
    "\n",
    "            speaker_durations[speaker] += duration\n",
    "            speaker_turns[speaker] += 1\n",
    "            audio_end = max(audio_end, end)\n",
    "\n",
    "        # Если сегментов нет — пропустить\n",
    "        if not segments:\n",
    "            continue\n",
    "\n",
    "        # Сортировка по времени начала для анализа пауз\n",
    "        segments_sorted = sorted(segments, key=lambda x: x[0])\n",
    "\n",
    "        # Расчёт пауз\n",
    "        pauses = [\n",
    "            segments_sorted[i + 1][0] - segments_sorted[i][1]\n",
    "            for i in range(len(segments_sorted) - 1)\n",
    "            if segments_sorted[i + 1][0] > segments_sorted[i][1]\n",
    "        ]\n",
    "\n",
    "        # Скалярные признаки\n",
    "        total_segments = len(segments)\n",
    "        durations = [s[2] for s in segments]\n",
    "        total_speech = sum(durations)\n",
    "\n",
    "        row = {\n",
    "            \"filename\": filename,\n",
    "            \"duration\": round(audio_end, 2),\n",
    "            \"speakers_count\": len(speaker_durations),\n",
    "            \"total_segments\": total_segments,\n",
    "            \"avg_segment_duration\": round(np.mean(durations), 2),\n",
    "            \"std_segment_duration\": round(np.std(durations), 2),\n",
    "            \"max_speaker_duration\": round(max(speaker_durations.values()), 2),\n",
    "            \"min_speaker_duration\": round(min(speaker_durations.values()), 2),\n",
    "            \"dominant_speaker_ratio\": round(max(speaker_durations.values()) / total_speech, 2),\n",
    "            \"speaking_turns_diff\": max(speaker_turns.values()) - min(speaker_turns.values()),\n",
    "            \"speech_density\": round(total_speech / audio_end, 2),\n",
    "            \"avg_pause_between_segments\": round(np.mean(pauses), 2) if pauses else 0.0,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "         row = {\n",
    "            \"filename\": filename,\n",
    "            \"duration\": 0,\n",
    "            \"speakers_count\": 0,\n",
    "            \"total_segments\": 0,\n",
    "            \"avg_segment_duration\": 0,\n",
    "            \"std_segment_duration\": 0,\n",
    "            \"max_speaker_duration\": 0,\n",
    "            \"min_speaker_duration\": 0,\n",
    "            \"dominant_speaker_ratio\": 0,\n",
    "            \"speaking_turns_diff\": 0,\n",
    "            \"speech_density\": 0,\n",
    "            \"avg_pause_between_segments\": 0}\n",
    "         print(e)\n",
    "    results.append(row)\n",
    "\n",
    "# В DataFrame\n",
    "df_scalar = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52bfb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scalar.to_parquet('./data_features/audio_diarization.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # === MFCC ===\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    features.extend(mfcc_mean)\n",
    "    features.extend(mfcc_std)\n",
    "\n",
    "    # === Chroma (может не работать с низким sr) ===\n",
    "    try:\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        features.extend(chroma_mean)\n",
    "    except Exception as e:\n",
    "        print(f\"[CHROMA] Пропущено ({file_path}): {e}\")\n",
    "        features.extend([0.0] * 12)\n",
    "\n",
    "    # === Spectral contrast с безопасным n_bands ===\n",
    "    try:\n",
    "        fmin = 200.0\n",
    "        max_n_bands = int(np.floor(np.log2((sr / 2) / fmin)))\n",
    "        n_bands = min(6, max_n_bands)\n",
    "\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr, fmin=fmin, n_bands=n_bands)\n",
    "        contrast_mean = np.mean(contrast, axis=1)\n",
    "        features.extend(contrast_mean)\n",
    "    except Exception as e:\n",
    "        print(f\"[CONTRAST] Пропущено ({file_path}): {e}\")\n",
    "        features.extend([0.0] * 7)\n",
    "\n",
    "    # === Zero Crossing Rate ===\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "\n",
    "    return np.barray(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd2426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2896678922ce436a8c2cefd97e271d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
      "  warnings.warn(\n",
      "/opt/anaconda/lib/python3.11/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't extend empty axis 0 using modes other than 'constant' or 'empty'\n",
      "can't extend empty axis 0 using modes other than 'constant' or 'empty'\n"
     ]
    }
   ],
   "source": [
    "folder_path = './new_audiofiles/audiofiles'\n",
    "data = []\n",
    "second_data = []\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    try:\n",
    "        if filename.endswith(\".wav\"):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            features = extract_features(filepath)\n",
    "            data.append([filename] + list(features))\n",
    "    except Exception as e:\n",
    "        second_data.append(filename)\n",
    "        print(e)\n",
    "\n",
    "# Преобразуем в DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['applicationid'] + [f'audio_feature_{i}' for i in range(len(df.columns[1:]))]\n",
    "df.to_parquet('./data_features/audio_features.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
